# ==============================================================================
# ENVIRONMENT VARIABLES FOR STOCK RESEARCH ASSISTANT
# ==============================================================================
# Copy this file to .env and fill in your actual values
# IMPORTANT: Never commit .env to git (it's in .gitignore)
#

# ------------------------------------------------------------------------------
# OpenAI Configuration (Required for embeddings)
# ------------------------------------------------------------------------------
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here


# ------------------------------------------------------------------------------
# Qdrant Vector Database Configuration
# ------------------------------------------------------------------------------
# OPTION 1: Local Storage (Default - No setup needed)
# Just leave these commented out and specify path in code
#
# OPTION 2: Qdrant Cloud (Recommended for production)
# Sign up at: https://cloud.qdrant.io
# Get your cluster URL and API key from the dashboard
QDRANT_URL=https://your-cluster-id.cloud.qdrant.io
QDRANT_API_KEY=your-qdrant-api-key-here
#
# OPTION 3: Local Docker Server
# Run: docker run -p 6333:6333 qdrant/qdrant
# Then leave QDRANT_URL commented out (will use localhost:6333)


# ------------------------------------------------------------------------------
# Optional: Force cloud mode even if URL is not set
# ------------------------------------------------------------------------------
# QDRANT_USE_CLOUD=true


# ==============================================================================
# LLM CONFIGURATION FOR Q&A (Question Answering)
# ==============================================================================

# ------------------------------------------------------------------------------
# OpenAI Model Selection
# ------------------------------------------------------------------------------
# Model to use for answer generation
# Options:
#   - gpt-4-turbo-preview (recommended - best quality, ~$0.01-0.03/query)
#   - gpt-4 (high quality but more expensive)
#   - gpt-3.5-turbo (cheaper - ~$0.002/query, lower quality)
OPENAI_MODEL=gpt-4-turbo-preview

# ------------------------------------------------------------------------------
# Generation Parameters
# ------------------------------------------------------------------------------
# Temperature: Controls randomness (0.0 = deterministic, 2.0 = very random)
# Lower values (0.1-0.3) recommended for factual financial Q&A
OPENAI_TEMPERATURE=0.1

# Maximum tokens in generated response
# Typical answer = 200-500 tokens
# Max recommendation = 1000 to control costs
OPENAI_MAX_TOKENS=1000

# ------------------------------------------------------------------------------
# Retrieval Parameters
# ------------------------------------------------------------------------------
# Default number of chunks to retrieve for context
# Higher = more context but higher cost
# Recommended: 3-7 chunks
QA_TOP_K_DEFAULT=5

# Minimum similarity score threshold (0.0-1.0)
# Only retrieve chunks with score >= this value
# 0.0 = retrieve all, 0.7 = only high-confidence matches
QA_MIN_SIMILARITY_SCORE=0.0

# ------------------------------------------------------------------------------
# Local Qdrant Storage Path (if not using cloud)
# ------------------------------------------------------------------------------
QDRANT_PATH=data/processed/qdrant_storage
